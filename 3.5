# -------------------------------------------------------------- #
# from IPython.display import display
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import mglearn
# -------------------------------------------------------------- #
from sklearn.datasets import make_blobs
from sklearn.cluster import KMeans
# two_moons 데이터를 생성합니다(이번에는 노이즈를 조금만 넣습니다) p217
from sklearn.datasets import make_moons
# -------------------------------------------------------------- #
# 3.5.1 k-평균 군집
# mglearn.plots.plot_kmeans_algorithm()
# plt.show()
# mglearn.plots.plot_kmeans_boundaries()
# plt.show()

# 인위적으로 2차원 데이터를 생성합니다.
# X, y = make_blobs(random_state=1)
# 군집 모델을 만듭니다.
# kmeans = KMeans(n_clusters=3)
# kmeans.fit(X)
# print("클러스터 레이블 :\n {}".format(kmeans.labels_))
# print(kmeans.predict(X))
# mglearn.discrete_scatter(X[:, 0], X[:, 1], kmeans.labels_, markers='o')
# mglearn.discrete_scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], [0, 1, 2], markers='^', markeredgewidth=2)
# plt.show()

# fig, axes = plt.subplots(1, 2, figsize=(10, 5))
# 두 개의 클러스터 중심을 사용합니다.
# kmeans = KMeans(n_clusters=2)
# kmeans.fit(X)
# assignments = kmeans.labels_
# mglearn.discrete_scatter(X[:, 0],X[:, 1], assignments, ax=axes[0])

# 다섯 개의 클러스터 중심을 사용합니다.
# kmeans = KMeans(n_clusters=5)
# kmeans.fit(X)
# assignments = kmeans.labels_
# mglearn.discrete_scatter(X[:, 0], X[:, 1], assignments, ax=axes[1])
# plt.legend()
# plt.show()

# X_varied, y_varied = make_blobs(n_samples=200, cluster_std=[1.0, 2.5, 0.5], random_state=170)
# y_pred = KMeans(n_clusters=3, random_state=0).fit_predict(X_varied)
# mglearn.discrete_scatter(X_varied[:, 0], X_varied[:, 1], y_pred)
# plt.legend()
# plt.xlabel("att 0")
# plt.ylabel("att 1")
# plt.show()

# 무작위로 클러스터 데이터를 생성합니다. p216
# X, y = make_blobs(random_state=170, n_samples=600)
# rng = np.random.RandomState(74)
# 데이터가 길게 늘어지도록 변경합니다.
# transformation = rng.normal(size=(2, 2))
# X = np.dot(X, transformation)
# 세 개의 클러스터로 데이터에 KMean 알고리즘을 적용합니다.
# kmeans = KMeans(n_clusters=3)
# kmeans.fit(X)
# y_pred = kmeans.predict(X)
# 클러스터 할당과 클러스터 중심을 나타냅니다.
# mglearn.discrete_scatter(X[:, 0], X[:, 1], kmeans.labels_, markers='o')
# mglearn.discrete_scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], [0, 1, 2], markers='^', markeredgewidth=2)
# plt.xlabel("att 0")
# plt.ylabel("att 1")
# plt.legend()
# plt.show()

# two_moons 데이터를 생성합니다(이번에는 노이즈를 조금만 넣습니다) p217
# X, y = make_moons(n_samples=200, noise=0.05, random_state=0)
# 두 개의 클러스터로 데이터에 KMeans 알고리즘을 적용합니다.
# kmeans = KMeans(n_clusters=2)
# kmeans.fit(X)
# y_pred = kmeans.predict(X)
# 클러스터 할당과 클러스터 중심을 표시합니다.
# plt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap=mglearn.cm2, s=60, edgecolors='k')
# plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], marker='^', c=[mglearn.cm2(0), mglearn.cm2(1)], s=100, linewidths=2, edgecolors='k')
# plt.xlabel("Feature 0")
# plt.ylabel("Feature 1")
# plt.show()

